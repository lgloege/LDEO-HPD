{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flux figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "%config InlineBackend.print_figure_kwargs = {'dpi':300, 'bbox_inches': 'tight'}\n",
    "\n",
    "# standard imports\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# modeling\n",
    "import sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pgml\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# plotting\n",
    "import cmocean as cm\n",
    "import matplotlib as mpl\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from plotting_tools.spatial_map import SpatialMap\n",
    "from plotting_tools.time_series_diagram import TimeSeriesPlot\n",
    "\n",
    "# regression metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import max_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "#from sklearn.metrics import explained_variance_score\n",
    "\n",
    "import pgml\n",
    "import os\n",
    "# settings \n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir_raw = '/local/data/artemis/workspace/gloege/SOCAT-LE/data/raw'\n",
    "#dir_clean = '/local/data/artemis/workspace/gloege/SOCAT-LE/data/clean'\n",
    "dir_figs = '/home/gloege/projects/ldeo_hpd/reports/figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ================================================\n",
    "### force time vector to be proper format and range\n",
    "### ================================================\n",
    "def make_dates(start=None, end=None):\n",
    "    '''\n",
    "    Creates a monthly DateTime64 vector centered on 15th each month\n",
    "    \n",
    "    Input\n",
    "    =========\n",
    "    start : str 'YYYY-MM'\n",
    "    end :   str 'YYYY-MM'\n",
    "            \n",
    "    Output\n",
    "    =========\n",
    "    dates : dataArray \n",
    "    \n",
    "    Example\n",
    "    ==========\n",
    "    dates = make_dates(start='1990-01', end='2017-12')\n",
    "    '''\n",
    "    dates = pd.date_range(start=f'{start}-01T00:00:00.000000000', \n",
    "                          end=f'{end}-01T00:00:00.000000000',\n",
    "                          freq='MS')+ np.timedelta64(14, 'D')\n",
    "    da = xr.DataArray(dates, dims='time')\n",
    "    \n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_datetime64(times, use_cftime):\n",
    "    \"\"\"\n",
    "    Return times as np.datetime64[ns] or cftime.DatetimeProlepticGregorian\n",
    "    depending on whether the dates fall within the inclusive bounds of \n",
    "    np.datetime64[ns]: [1678-01-01 AD, 2261-12-31 AD].\n",
    "\n",
    "    Alternatively, always returns as cftime.DatetimeProlepticGregorian if\n",
    "    `use_cf_time` is True.\n",
    "    \n",
    "    source : https://gitlab.com/deltares/imod/imod-python/commit/9b1ae0e9a51b0fefe6ef86c2a2f9ef988024b464\n",
    "    \"\"\"\n",
    "    out_of_bounds = False\n",
    "    if use_cftime:\n",
    "        converted = [\n",
    "            cftime.DatetimeProlepticGregorian(*time.timetuple()[:6]) for time in times\n",
    "        ]\n",
    "    else:\n",
    "        for time in times:\n",
    "            year = time.year\n",
    "            if year < 1678 or year > 2261:\n",
    "                out_of_bounds = True\n",
    "                break\n",
    "\n",
    "        if out_of_bounds:\n",
    "            warnings.warn(\n",
    "                \"Dates are outside of np.datetime64[ns] timespan.\"\n",
    "                \"Converting to cftime.DatetimeProlepticGregorian.\"\n",
    "            )\n",
    "            converted = [\n",
    "                cftime.DatetimeProlepticGregorian(*time.timetuple()[:6]) for time in times\n",
    "            ]\n",
    "        else:\n",
    "            converted = [np.datetime64(time, \"ns\") for time in times]\n",
    "\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area(lat, dlat=1, dlon=1):\n",
    "    '''\n",
    "    WGS 84: https://earth-info.nga.mil/GandG/publications/tr8350.2/tr8350.2-a/Chapter%203.pdf\n",
    "    look table 3.7\n",
    "    \n",
    "    using the WGS 84 ellipsoid \n",
    "    \n",
    "    R equation is here: https://planetcalc.com/7721/\n",
    "    '''\n",
    "    deg_to_rad = np.pi/180\n",
    "    dlat_r = dlat * deg_to_rad\n",
    "    dlon_r = dlon * deg_to_rad\n",
    "    lat_r = lat * deg_to_rad\n",
    "    \n",
    "    # radius by latitude assuming oblate spheroid\n",
    "    # using a and b from WGS 84\n",
    "    # I rounded b from 6356752.3142\n",
    "    a = 6378137 # semimajor (m)\n",
    "    b = 6356752 # semiminor (m)\n",
    "    numer = ( (a**2 * np.cos(lat_r))**2 + (b**2 * np.sin(lat_r))**2 )\n",
    "    denom = ( (a * np.cos(lat_r))**2 + (b * np.sin(lat_r))**2 )\n",
    "    R = np.sqrt(numer / denom) # radius of earth \n",
    "    \n",
    "    return R * R * dlat_r * dlon_r  * np.cos(lat_r)\n",
    "\n",
    "## broadcast area to lon and time\n",
    "#lon = np.arange(0.5,360,1)\n",
    "#time = pd.date_range(start='1982-01-01T00:00:00.000000000', \n",
    "#                     end='2016-12-01T00:00:00.000000000',freq='MS')+ np.timedelta64(14, 'D')\n",
    "#ds_bc = xr.DataArray(np.zeros([len(time),len(lon)]), coords=[('time', time),('lon', lon)])\n",
    "#ds_data, ds_mask = xr.broadcast(area(ds_hpd['lat']), ds_bc)\n",
    "#ds_data = ds_data.transpose('time','lat','lon')\n",
    "#ds_area = ds_data.rename('area').to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load HPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 ms, sys: 6.92 ms, total: 12.7 ms\n",
      "Wall time: 37.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_hpd = xr.open_dataset('/local/data/artemis/workspace/gloege/ldeo-hpd/LDEO-HPD_fgco2_v20210426_1x1_198201-201812.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_prod = xr.open_dataset('/local/data/artemis/workspace/gloege/gregor/IPCC-AR6_FCO2_DataProducts_filled_20201118.nc')\n",
    "\n",
    "ds_prod['lon'] = [lon if lon>0 else lon+360 for lon in ds_prod['lon'].values]\n",
    "ds_prod['time'] = pd.date_range(\n",
    "    start=f'1985-01-01T00:00:00.000000000', \n",
    "    end=f'2018-12-01T00:00:00.000000000',\n",
    "    freq='MS') + np.timedelta64(14, 'D')\n",
    "\n",
    "ds_prod['fgco2'] = ds_prod['fgco2']*365\n",
    "ds_prod['fgco2'].attrs = {'description':'Air-sea CO2 fluxes, where negative is into the ocean',\n",
    "                         'units':'mol/m2/yr'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flux density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_den_mod = pd.read_csv('/local/data/artemis/workspace/gloege/GCB/GCB2020_fluxes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_den_mod['Mean models'] = flux_den_mod['Mean models']*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years</th>\n",
       "      <th>CESM-ETH</th>\n",
       "      <th>CSIRO</th>\n",
       "      <th>FESOM</th>\n",
       "      <th>MPI</th>\n",
       "      <th>CNRM</th>\n",
       "      <th>PlankTOM</th>\n",
       "      <th>NorESM</th>\n",
       "      <th>Princeton</th>\n",
       "      <th>IPSL</th>\n",
       "      <th>Mean models</th>\n",
       "      <th>model std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1959</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1962</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.19</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1963</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   years  CESM-ETH  CSIRO  FESOM   MPI  CNRM  PlankTOM  NorESM  Princeton  \\\n",
       "0   1959      0.95   1.03   1.01  0.80  0.79      0.89    1.10       0.35   \n",
       "1   1960      0.89   1.03   1.03  0.73  0.77      0.84    1.07       0.48   \n",
       "2   1961      0.62   0.89   0.90  0.72  0.50      0.80    1.01       0.42   \n",
       "3   1962      0.72   1.00   0.84  0.65  0.44      0.94    1.19       0.51   \n",
       "4   1963      0.90   1.18   0.93  0.72  0.63      1.06    1.35       0.66   \n",
       "\n",
       "   IPSL  Mean models  model std  \n",
       "0  0.83        -0.86       0.22  \n",
       "1  0.71        -0.84       0.19  \n",
       "2  0.59        -0.72       0.20  \n",
       "3  0.62        -0.77       0.24  \n",
       "4  0.81        -0.92       0.24  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flux_den_mod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prodcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloege/.conda/envs/tensorflow/lib/python3.7/site-packages/xarray/core/nanops.py:140: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "flux_den_prods = (ds_prod['fgco2'].mean('wind')*(12.01/10**15)*ds_prod['area']).sum(['lat','lon'])\n",
    "flux_den_prods_yr = flux_den_prods.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decdal mean flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_spco2  = xr.open_dataset('/local/data/artemis/workspace/gloege/ldeo-hpd/LDEO-HPD_spco2_v20210426_1x1_198201-201812.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloege/.conda/envs/tensorflow/lib/python3.7/site-packages/xarray/core/nanops.py:140: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "mask = (ds_spco2['spco2'].sel(model='cesm').mean('time')>0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.pcolor(mask)\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.8 s, sys: 5.79 s, total: 8.59 s\n",
      "Wall time: 8.67 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gloege/.conda/envs/tensorflow/lib/python3.7/site-packages/xarray/core/nanops.py:140: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_tmp = xr.open_dataset('/local/data/artemis/workspace/gloege/ldeo-hpd/LDEO-HPD_fgco2_v20210426_1x1_198201-201812.nc')\n",
    "ds_fgco2 = ds_tmp ['fgco2_avg'].mean('model')\n",
    "ds_area = ds_tmp['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfilled  Filled\n",
      "-1.38, -1.53\n",
      "\n",
      "-1.48, -1.65\n",
      "\n",
      "-1.49, -1.69\n",
      "\n",
      "-1.96, -2.23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total area of ocean\n",
    "#total_area = ds_area.sum()\n",
    "\n",
    "# calculate regional averages (mol/m2/s)\n",
    "grams_in_mol = 12.01            # g/mol\n",
    "sec_to_year = 86400 * 365       # sec/year\n",
    "gram_to_petagram = 1 / (10**15) # Pg/g\n",
    "\n",
    "# conversion to mol/s to Pg/yr\n",
    "conversion = grams_in_mol * gram_to_petagram * sec_to_year\n",
    "\n",
    "# time ranges \n",
    "slices = [slice('1982-01','1989-12'),\n",
    "          slice('1990-01','1999-12'),\n",
    "          slice('2000-01','2009-12'),\n",
    "          slice('2010-01','2018-12')]\n",
    "\n",
    "print('Unfilled  Filled')\n",
    "for time_range in slices:\n",
    "    filled = ((((ds_fgco2*conversion)*ds_area).sum(['lat','lon']))).sel(time=time_range).mean('time').values\n",
    "    unfilled = ((((ds_fgco2*conversion)*ds_area*mask).sum(['lat','lon']))).sel(time=time_range).mean('time').values\n",
    "    print(f'{unfilled:0.3}, {filled:0.3}')\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
